{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"하이퍼파라미터 설정하기.\n",
    "\"\"\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"훈련 및 테스트 데이터세트 준비하기.\n",
    "\"\"\"\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"훈련 및 테스트 데이터로더 준비하기.\n",
    "\"\"\"\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE)\n",
    "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"신경망 만들기.\n",
    "Linear > ReLU > Linear > ReLU > Linear\n",
    "\"\"\"\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"훈련 루프\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # 모델을 학습모드로 설정 (배치정규화batch normalization 및 드롭아웃dropout 레이어들에 중요함)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # X: 데이터, y: 정답 레이블\n",
    "\n",
    "        # 추론 후 손실 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # 역전파에서 수집된 변화도로 매개변수를 조정함.\n",
    "        optimizer.step()\n",
    "\n",
    "        # 변화도를 0으로 재설정\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch * BATCH_SIZE + len(X)\n",
    "            print(f\"iter: {batch:>5d}, loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"테스트 루프\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델을 평가모드로 설정한다 (배치정규화 및 드롭아웃 레이어들에 중요함)\n",
    "    model.eval()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # torch.no_grad 컨텍스트 매니저를 사용하여 변화도gradient를 계산하지 않도록 한다.\n",
    "    # requires_grad=True로 설정된 텐서들의 불필요한 변화도 연산 및 메모리 사용량을 줄여준다.\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Accuracy: {(100*correct):>0.1f}% / Avg loss: {test_loss:>8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "\n",
      "Epoch   1\n",
      "---------\n",
      "iter:     0, loss: 2.297871  [   64/60000]\n",
      "iter:   100, loss: 2.291607  [ 6464/60000]\n",
      "iter:   200, loss: 2.264092  [12864/60000]\n",
      "iter:   300, loss: 2.263625  [19264/60000]\n",
      "iter:   400, loss: 2.258106  [25664/60000]\n",
      "iter:   500, loss: 2.204788  [32064/60000]\n",
      "iter:   600, loss: 2.224358  [38464/60000]\n",
      "iter:   700, loss: 2.175654  [44864/60000]\n",
      "iter:   800, loss: 2.189482  [51264/60000]\n",
      "iter:   900, loss: 2.149080  [57664/60000]\n",
      "Accuracy: 41.2% / Avg loss: 2.147065\n",
      "\n",
      "Epoch   2\n",
      "---------\n",
      "iter:     0, loss: 2.165552  [   64/60000]\n",
      "iter:   100, loss: 2.153446  [ 6464/60000]\n",
      "iter:   200, loss: 2.090282  [12864/60000]\n",
      "iter:   300, loss: 2.105554  [19264/60000]\n",
      "iter:   400, loss: 2.068941  [25664/60000]\n",
      "iter:   500, loss: 1.994585  [32064/60000]\n",
      "iter:   600, loss: 2.025207  [38464/60000]\n",
      "iter:   700, loss: 1.936219  [44864/60000]\n",
      "iter:   800, loss: 1.957595  [51264/60000]\n",
      "iter:   900, loss: 1.872978  [57664/60000]\n",
      "Accuracy: 55.9% / Avg loss: 1.874676\n",
      "\n",
      "Epoch   3\n",
      "---------\n",
      "iter:     0, loss: 1.922801  [   64/60000]\n",
      "iter:   100, loss: 1.884534  [ 6464/60000]\n",
      "iter:   200, loss: 1.762486  [12864/60000]\n",
      "iter:   300, loss: 1.799629  [19264/60000]\n",
      "iter:   400, loss: 1.702718  [25664/60000]\n",
      "iter:   500, loss: 1.649210  [32064/60000]\n",
      "iter:   600, loss: 1.667551  [38464/60000]\n",
      "iter:   700, loss: 1.556787  [44864/60000]\n",
      "iter:   800, loss: 1.598797  [51264/60000]\n",
      "iter:   900, loss: 1.483132  [57664/60000]\n",
      "Accuracy: 59.3% / Avg loss: 1.504607\n",
      "\n",
      "Epoch   4\n",
      "---------\n",
      "iter:     0, loss: 1.585973  [   64/60000]\n",
      "iter:   100, loss: 1.541692  [ 6464/60000]\n",
      "iter:   200, loss: 1.389413  [12864/60000]\n",
      "iter:   300, loss: 1.459874  [19264/60000]\n",
      "iter:   400, loss: 1.349023  [25664/60000]\n",
      "iter:   500, loss: 1.342177  [32064/60000]\n",
      "iter:   600, loss: 1.355999  [38464/60000]\n",
      "iter:   700, loss: 1.264841  [44864/60000]\n",
      "iter:   800, loss: 1.313551  [51264/60000]\n",
      "iter:   900, loss: 1.214292  [57664/60000]\n",
      "Accuracy: 63.1% / Avg loss: 1.240672\n",
      "\n",
      "Epoch   5\n",
      "---------\n",
      "iter:     0, loss: 1.326855  [   64/60000]\n",
      "iter:   100, loss: 1.301433  [ 6464/60000]\n",
      "iter:   200, loss: 1.136078  [12864/60000]\n",
      "iter:   300, loss: 1.241643  [19264/60000]\n",
      "iter:   400, loss: 1.119882  [25664/60000]\n",
      "iter:   500, loss: 1.145072  [32064/60000]\n",
      "iter:   600, loss: 1.168264  [38464/60000]\n",
      "iter:   700, loss: 1.088212  [44864/60000]\n",
      "iter:   800, loss: 1.137730  [51264/60000]\n",
      "iter:   900, loss: 1.061736  [57664/60000]\n",
      "Accuracy: 64.7% / Avg loss: 1.079891\n",
      "\n",
      "Epoch   6\n",
      "---------\n",
      "iter:     0, loss: 1.156777  [   64/60000]\n",
      "iter:   100, loss: 1.154390  [ 6464/60000]\n",
      "iter:   200, loss: 0.973258  [12864/60000]\n",
      "iter:   300, loss: 1.108231  [19264/60000]\n",
      "iter:   400, loss: 0.981181  [25664/60000]\n",
      "iter:   500, loss: 1.014446  [32064/60000]\n",
      "iter:   600, loss: 1.053655  [38464/60000]\n",
      "iter:   700, loss: 0.977324  [44864/60000]\n",
      "iter:   800, loss: 1.025580  [51264/60000]\n",
      "iter:   900, loss: 0.967926  [57664/60000]\n",
      "Accuracy: 65.8% / Avg loss: 0.977548\n",
      "\n",
      "Epoch   7\n",
      "---------\n",
      "iter:     0, loss: 1.040455  [   64/60000]\n",
      "iter:   100, loss: 1.060866  [ 6464/60000]\n",
      "iter:   200, loss: 0.863074  [12864/60000]\n",
      "iter:   300, loss: 1.020870  [19264/60000]\n",
      "iter:   400, loss: 0.894051  [25664/60000]\n",
      "iter:   500, loss: 0.923206  [32064/60000]\n",
      "iter:   600, loss: 0.978637  [38464/60000]\n",
      "iter:   700, loss: 0.905444  [44864/60000]\n",
      "iter:   800, loss: 0.948823  [51264/60000]\n",
      "iter:   900, loss: 0.905305  [57664/60000]\n",
      "Accuracy: 67.1% / Avg loss: 0.908115\n",
      "\n",
      "Epoch   8\n",
      "---------\n",
      "iter:     0, loss: 0.954928  [   64/60000]\n",
      "iter:   100, loss: 0.996256  [ 6464/60000]\n",
      "iter:   200, loss: 0.784309  [12864/60000]\n",
      "iter:   300, loss: 0.959998  [19264/60000]\n",
      "iter:   400, loss: 0.835366  [25664/60000]\n",
      "iter:   500, loss: 0.856468  [32064/60000]\n",
      "iter:   600, loss: 0.925675  [38464/60000]\n",
      "iter:   700, loss: 0.857428  [44864/60000]\n",
      "iter:   800, loss: 0.893966  [51264/60000]\n",
      "iter:   900, loss: 0.860332  [57664/60000]\n",
      "Accuracy: 68.3% / Avg loss: 0.858245\n",
      "\n",
      "Epoch   9\n",
      "---------\n",
      "iter:     0, loss: 0.889276  [   64/60000]\n",
      "iter:   100, loss: 0.947456  [ 6464/60000]\n",
      "iter:   200, loss: 0.725246  [12864/60000]\n",
      "iter:   300, loss: 0.915179  [19264/60000]\n",
      "iter:   400, loss: 0.792998  [25664/60000]\n",
      "iter:   500, loss: 0.806436  [32064/60000]\n",
      "iter:   600, loss: 0.885076  [38464/60000]\n",
      "iter:   700, loss: 0.823703  [44864/60000]\n",
      "iter:   800, loss: 0.853162  [51264/60000]\n",
      "iter:   900, loss: 0.825659  [57664/60000]\n",
      "Accuracy: 69.6% / Avg loss: 0.820315\n",
      "\n",
      "Epoch  10\n",
      "---------\n",
      "iter:     0, loss: 0.836374  [   64/60000]\n",
      "iter:   100, loss: 0.907832  [ 6464/60000]\n",
      "iter:   200, loss: 0.678931  [12864/60000]\n",
      "iter:   300, loss: 0.880556  [19264/60000]\n",
      "iter:   400, loss: 0.760595  [25664/60000]\n",
      "iter:   500, loss: 0.767816  [32064/60000]\n",
      "iter:   600, loss: 0.851862  [38464/60000]\n",
      "iter:   700, loss: 0.798502  [44864/60000]\n",
      "iter:   800, loss: 0.821275  [51264/60000]\n",
      "iter:   900, loss: 0.797290  [57664/60000]\n",
      "Accuracy: 70.8% / Avg loss: 0.789873\n",
      "\n",
      "Epoch  11\n",
      "---------\n",
      "iter:     0, loss: 0.792108  [   64/60000]\n",
      "iter:   100, loss: 0.873817  [ 6464/60000]\n",
      "iter:   200, loss: 0.641282  [12864/60000]\n",
      "iter:   300, loss: 0.852477  [19264/60000]\n",
      "iter:   400, loss: 0.734280  [25664/60000]\n",
      "iter:   500, loss: 0.737098  [32064/60000]\n",
      "iter:   600, loss: 0.823278  [38464/60000]\n",
      "iter:   700, loss: 0.778389  [44864/60000]\n",
      "iter:   800, loss: 0.795281  [51264/60000]\n",
      "iter:   900, loss: 0.773166  [57664/60000]\n",
      "Accuracy: 72.0% / Avg loss: 0.764284\n",
      "\n",
      "Epoch  12\n",
      "---------\n",
      "iter:     0, loss: 0.753865  [   64/60000]\n",
      "iter:   100, loss: 0.843390  [ 6464/60000]\n",
      "iter:   200, loss: 0.609635  [12864/60000]\n",
      "iter:   300, loss: 0.829125  [19264/60000]\n",
      "iter:   400, loss: 0.712193  [25664/60000]\n",
      "iter:   500, loss: 0.711829  [32064/60000]\n",
      "iter:   600, loss: 0.797723  [38464/60000]\n",
      "iter:   700, loss: 0.761523  [44864/60000]\n",
      "iter:   800, loss: 0.773316  [51264/60000]\n",
      "iter:   900, loss: 0.751875  [57664/60000]\n",
      "Accuracy: 73.3% / Avg loss: 0.741956\n",
      "\n",
      "Epoch  13\n",
      "---------\n",
      "iter:     0, loss: 0.720216  [   64/60000]\n",
      "iter:   100, loss: 0.815550  [ 6464/60000]\n",
      "iter:   200, loss: 0.582345  [12864/60000]\n",
      "iter:   300, loss: 0.809023  [19264/60000]\n",
      "iter:   400, loss: 0.693246  [25664/60000]\n",
      "iter:   500, loss: 0.690792  [32064/60000]\n",
      "iter:   600, loss: 0.774319  [38464/60000]\n",
      "iter:   700, loss: 0.746655  [44864/60000]\n",
      "iter:   800, loss: 0.754169  [51264/60000]\n",
      "iter:   900, loss: 0.732447  [57664/60000]\n",
      "Accuracy: 74.2% / Avg loss: 0.721959\n",
      "\n",
      "Epoch  14\n",
      "---------\n",
      "iter:     0, loss: 0.690183  [   64/60000]\n",
      "iter:   100, loss: 0.789720  [ 6464/60000]\n",
      "iter:   200, loss: 0.558379  [12864/60000]\n",
      "iter:   300, loss: 0.791197  [19264/60000]\n",
      "iter:   400, loss: 0.676814  [25664/60000]\n",
      "iter:   500, loss: 0.672851  [32064/60000]\n",
      "iter:   600, loss: 0.752550  [38464/60000]\n",
      "iter:   700, loss: 0.733159  [44864/60000]\n",
      "iter:   800, loss: 0.737093  [51264/60000]\n",
      "iter:   900, loss: 0.714510  [57664/60000]\n",
      "Accuracy: 75.0% / Avg loss: 0.703750\n",
      "\n",
      "Epoch  15\n",
      "---------\n",
      "iter:     0, loss: 0.663107  [   64/60000]\n",
      "iter:   100, loss: 0.765567  [ 6464/60000]\n",
      "iter:   200, loss: 0.537097  [12864/60000]\n",
      "iter:   300, loss: 0.775234  [19264/60000]\n",
      "iter:   400, loss: 0.662302  [25664/60000]\n",
      "iter:   500, loss: 0.657361  [32064/60000]\n",
      "iter:   600, loss: 0.732233  [38464/60000]\n",
      "iter:   700, loss: 0.720817  [44864/60000]\n",
      "iter:   800, loss: 0.721720  [51264/60000]\n",
      "iter:   900, loss: 0.697854  [57664/60000]\n",
      "Accuracy: 75.7% / Avg loss: 0.687022\n",
      "\n",
      "Epoch  16\n",
      "---------\n",
      "iter:     0, loss: 0.638681  [   64/60000]\n",
      "iter:   100, loss: 0.743112  [ 6464/60000]\n",
      "iter:   200, loss: 0.517937  [12864/60000]\n",
      "iter:   300, loss: 0.760560  [19264/60000]\n",
      "iter:   400, loss: 0.649474  [25664/60000]\n",
      "iter:   500, loss: 0.643723  [32064/60000]\n",
      "iter:   600, loss: 0.713307  [38464/60000]\n",
      "iter:   700, loss: 0.709670  [44864/60000]\n",
      "iter:   800, loss: 0.707919  [51264/60000]\n",
      "iter:   900, loss: 0.682272  [57664/60000]\n",
      "Accuracy: 76.4% / Avg loss: 0.671602\n",
      "\n",
      "Epoch  17\n",
      "---------\n",
      "iter:     0, loss: 0.616667  [   64/60000]\n",
      "iter:   100, loss: 0.722298  [ 6464/60000]\n",
      "iter:   200, loss: 0.500685  [12864/60000]\n",
      "iter:   300, loss: 0.746975  [19264/60000]\n",
      "iter:   400, loss: 0.638130  [25664/60000]\n",
      "iter:   500, loss: 0.631773  [32064/60000]\n",
      "iter:   600, loss: 0.695603  [38464/60000]\n",
      "iter:   700, loss: 0.699724  [44864/60000]\n",
      "iter:   800, loss: 0.695586  [51264/60000]\n",
      "iter:   900, loss: 0.667600  [57664/60000]\n",
      "Accuracy: 77.0% / Avg loss: 0.657355\n",
      "\n",
      "Epoch  18\n",
      "---------\n",
      "iter:     0, loss: 0.596697  [   64/60000]\n",
      "iter:   100, loss: 0.703007  [ 6464/60000]\n",
      "iter:   200, loss: 0.485235  [12864/60000]\n",
      "iter:   300, loss: 0.734282  [19264/60000]\n",
      "iter:   400, loss: 0.628057  [25664/60000]\n",
      "iter:   500, loss: 0.621322  [32064/60000]\n",
      "iter:   600, loss: 0.679070  [38464/60000]\n",
      "iter:   700, loss: 0.690929  [44864/60000]\n",
      "iter:   800, loss: 0.684861  [51264/60000]\n",
      "iter:   900, loss: 0.653873  [57664/60000]\n",
      "Accuracy: 77.6% / Avg loss: 0.644217\n",
      "\n",
      "Epoch  19\n",
      "---------\n",
      "iter:     0, loss: 0.578578  [   64/60000]\n",
      "iter:   100, loss: 0.685414  [ 6464/60000]\n",
      "iter:   200, loss: 0.471238  [12864/60000]\n",
      "iter:   300, loss: 0.722450  [19264/60000]\n",
      "iter:   400, loss: 0.619067  [25664/60000]\n",
      "iter:   500, loss: 0.612167  [32064/60000]\n",
      "iter:   600, loss: 0.663514  [38464/60000]\n",
      "iter:   700, loss: 0.683132  [44864/60000]\n",
      "iter:   800, loss: 0.675401  [51264/60000]\n",
      "iter:   900, loss: 0.641067  [57664/60000]\n",
      "Accuracy: 78.1% / Avg loss: 0.632099\n",
      "\n",
      "Epoch  20\n",
      "---------\n",
      "iter:     0, loss: 0.562211  [   64/60000]\n",
      "iter:   100, loss: 0.669228  [ 6464/60000]\n",
      "iter:   200, loss: 0.458507  [12864/60000]\n",
      "iter:   300, loss: 0.711323  [19264/60000]\n",
      "iter:   400, loss: 0.611002  [25664/60000]\n",
      "iter:   500, loss: 0.604080  [32064/60000]\n",
      "iter:   600, loss: 0.649105  [38464/60000]\n",
      "iter:   700, loss: 0.676382  [44864/60000]\n",
      "iter:   800, loss: 0.667076  [51264/60000]\n",
      "iter:   900, loss: 0.629119  [57664/60000]\n",
      "Accuracy: 78.3% / Avg loss: 0.620930\n",
      "\n",
      "Epoch  21\n",
      "---------\n",
      "iter:     0, loss: 0.547339  [   64/60000]\n",
      "iter:   100, loss: 0.654438  [ 6464/60000]\n",
      "iter:   200, loss: 0.446891  [12864/60000]\n",
      "iter:   300, loss: 0.700822  [19264/60000]\n",
      "iter:   400, loss: 0.603689  [25664/60000]\n",
      "iter:   500, loss: 0.596815  [32064/60000]\n",
      "iter:   600, loss: 0.635790  [38464/60000]\n",
      "iter:   700, loss: 0.670691  [44864/60000]\n",
      "iter:   800, loss: 0.659796  [51264/60000]\n",
      "iter:   900, loss: 0.617917  [57664/60000]\n",
      "Accuracy: 78.8% / Avg loss: 0.610636\n",
      "\n",
      "Epoch  22\n",
      "---------\n",
      "iter:     0, loss: 0.533811  [   64/60000]\n",
      "iter:   100, loss: 0.640913  [ 6464/60000]\n",
      "iter:   200, loss: 0.436279  [12864/60000]\n",
      "iter:   300, loss: 0.690871  [19264/60000]\n",
      "iter:   400, loss: 0.596942  [25664/60000]\n",
      "iter:   500, loss: 0.590184  [32064/60000]\n",
      "iter:   600, loss: 0.623469  [38464/60000]\n",
      "iter:   700, loss: 0.666002  [44864/60000]\n",
      "iter:   800, loss: 0.653490  [51264/60000]\n",
      "iter:   900, loss: 0.607314  [57664/60000]\n",
      "Accuracy: 79.2% / Avg loss: 0.601156\n",
      "\n",
      "Epoch  23\n",
      "---------\n",
      "iter:     0, loss: 0.521493  [   64/60000]\n",
      "iter:   100, loss: 0.628620  [ 6464/60000]\n",
      "iter:   200, loss: 0.426540  [12864/60000]\n",
      "iter:   300, loss: 0.681465  [19264/60000]\n",
      "iter:   400, loss: 0.590579  [25664/60000]\n",
      "iter:   500, loss: 0.584081  [32064/60000]\n",
      "iter:   600, loss: 0.612087  [38464/60000]\n",
      "iter:   700, loss: 0.662211  [44864/60000]\n",
      "iter:   800, loss: 0.648021  [51264/60000]\n",
      "iter:   900, loss: 0.597275  [57664/60000]\n",
      "Accuracy: 79.4% / Avg loss: 0.592419\n",
      "\n",
      "Epoch  24\n",
      "---------\n",
      "iter:     0, loss: 0.510173  [   64/60000]\n",
      "iter:   100, loss: 0.617339  [ 6464/60000]\n",
      "iter:   200, loss: 0.417601  [12864/60000]\n",
      "iter:   300, loss: 0.672652  [19264/60000]\n",
      "iter:   400, loss: 0.584439  [25664/60000]\n",
      "iter:   500, loss: 0.578406  [32064/60000]\n",
      "iter:   600, loss: 0.601549  [38464/60000]\n",
      "iter:   700, loss: 0.659181  [44864/60000]\n",
      "iter:   800, loss: 0.643264  [51264/60000]\n",
      "iter:   900, loss: 0.587614  [57664/60000]\n",
      "Accuracy: 79.6% / Avg loss: 0.584354\n",
      "\n",
      "Epoch  25\n",
      "---------\n",
      "iter:     0, loss: 0.499698  [   64/60000]\n",
      "iter:   100, loss: 0.606933  [ 6464/60000]\n",
      "iter:   200, loss: 0.409354  [12864/60000]\n",
      "iter:   300, loss: 0.664257  [19264/60000]\n",
      "iter:   400, loss: 0.578551  [25664/60000]\n",
      "iter:   500, loss: 0.573076  [32064/60000]\n",
      "iter:   600, loss: 0.591878  [38464/60000]\n",
      "iter:   700, loss: 0.656841  [44864/60000]\n",
      "iter:   800, loss: 0.639164  [51264/60000]\n",
      "iter:   900, loss: 0.578317  [57664/60000]\n",
      "Accuracy: 80.0% / Avg loss: 0.576889\n",
      "\n",
      "Epoch  26\n",
      "---------\n",
      "iter:     0, loss: 0.489945  [   64/60000]\n",
      "iter:   100, loss: 0.597338  [ 6464/60000]\n",
      "iter:   200, loss: 0.401783  [12864/60000]\n",
      "iter:   300, loss: 0.656314  [19264/60000]\n",
      "iter:   400, loss: 0.572751  [25664/60000]\n",
      "iter:   500, loss: 0.567995  [32064/60000]\n",
      "iter:   600, loss: 0.582948  [38464/60000]\n",
      "iter:   700, loss: 0.655169  [44864/60000]\n",
      "iter:   800, loss: 0.635581  [51264/60000]\n",
      "iter:   900, loss: 0.569409  [57664/60000]\n",
      "Accuracy: 80.2% / Avg loss: 0.569988\n",
      "\n",
      "Epoch  27\n",
      "---------\n",
      "iter:     0, loss: 0.480787  [   64/60000]\n",
      "iter:   100, loss: 0.588532  [ 6464/60000]\n",
      "iter:   200, loss: 0.394765  [12864/60000]\n",
      "iter:   300, loss: 0.648750  [19264/60000]\n",
      "iter:   400, loss: 0.566982  [25664/60000]\n",
      "iter:   500, loss: 0.563083  [32064/60000]\n",
      "iter:   600, loss: 0.574648  [38464/60000]\n",
      "iter:   700, loss: 0.654056  [44864/60000]\n",
      "iter:   800, loss: 0.632371  [51264/60000]\n",
      "iter:   900, loss: 0.560768  [57664/60000]\n",
      "Accuracy: 80.5% / Avg loss: 0.563582\n",
      "\n",
      "Epoch  28\n",
      "---------\n",
      "iter:     0, loss: 0.472172  [   64/60000]\n",
      "iter:   100, loss: 0.580431  [ 6464/60000]\n",
      "iter:   200, loss: 0.388249  [12864/60000]\n",
      "iter:   300, loss: 0.641551  [19264/60000]\n",
      "iter:   400, loss: 0.561258  [25664/60000]\n",
      "iter:   500, loss: 0.558292  [32064/60000]\n",
      "iter:   600, loss: 0.567019  [38464/60000]\n",
      "iter:   700, loss: 0.653417  [44864/60000]\n",
      "iter:   800, loss: 0.629469  [51264/60000]\n",
      "iter:   900, loss: 0.552371  [57664/60000]\n",
      "Accuracy: 80.7% / Avg loss: 0.557625\n",
      "\n",
      "Epoch  29\n",
      "---------\n",
      "iter:     0, loss: 0.464086  [   64/60000]\n",
      "iter:   100, loss: 0.572947  [ 6464/60000]\n",
      "iter:   200, loss: 0.382169  [12864/60000]\n",
      "iter:   300, loss: 0.634640  [19264/60000]\n",
      "iter:   400, loss: 0.555572  [25664/60000]\n",
      "iter:   500, loss: 0.553546  [32064/60000]\n",
      "iter:   600, loss: 0.559897  [38464/60000]\n",
      "iter:   700, loss: 0.653174  [44864/60000]\n",
      "iter:   800, loss: 0.626889  [51264/60000]\n",
      "iter:   900, loss: 0.544232  [57664/60000]\n",
      "Accuracy: 80.8% / Avg loss: 0.552081\n",
      "\n",
      "Epoch  30\n",
      "---------\n",
      "iter:     0, loss: 0.456491  [   64/60000]\n",
      "iter:   100, loss: 0.566071  [ 6464/60000]\n",
      "iter:   200, loss: 0.376501  [12864/60000]\n",
      "iter:   300, loss: 0.628114  [19264/60000]\n",
      "iter:   400, loss: 0.549951  [25664/60000]\n",
      "iter:   500, loss: 0.548921  [32064/60000]\n",
      "iter:   600, loss: 0.553231  [38464/60000]\n",
      "iter:   700, loss: 0.653297  [44864/60000]\n",
      "iter:   800, loss: 0.624652  [51264/60000]\n",
      "iter:   900, loss: 0.536466  [57664/60000]\n",
      "Accuracy: 80.9% / Avg loss: 0.546915\n",
      "\n",
      "Epoch  31\n",
      "---------\n",
      "iter:     0, loss: 0.449302  [   64/60000]\n",
      "iter:   100, loss: 0.559634  [ 6464/60000]\n",
      "iter:   200, loss: 0.371248  [12864/60000]\n",
      "iter:   300, loss: 0.621983  [19264/60000]\n",
      "iter:   400, loss: 0.544342  [25664/60000]\n",
      "iter:   500, loss: 0.544404  [32064/60000]\n",
      "iter:   600, loss: 0.547100  [38464/60000]\n",
      "iter:   700, loss: 0.653730  [44864/60000]\n",
      "iter:   800, loss: 0.622563  [51264/60000]\n",
      "iter:   900, loss: 0.528958  [57664/60000]\n",
      "Accuracy: 81.2% / Avg loss: 0.542096\n",
      "\n",
      "Epoch  32\n",
      "---------\n",
      "iter:     0, loss: 0.442481  [   64/60000]\n",
      "iter:   100, loss: 0.553679  [ 6464/60000]\n",
      "iter:   200, loss: 0.366373  [12864/60000]\n",
      "iter:   300, loss: 0.616144  [19264/60000]\n",
      "iter:   400, loss: 0.538821  [25664/60000]\n",
      "iter:   500, loss: 0.539942  [32064/60000]\n",
      "iter:   600, loss: 0.541463  [38464/60000]\n",
      "iter:   700, loss: 0.654335  [44864/60000]\n",
      "iter:   800, loss: 0.620590  [51264/60000]\n",
      "iter:   900, loss: 0.521733  [57664/60000]\n",
      "Accuracy: 81.3% / Avg loss: 0.537590\n",
      "\n",
      "Epoch  33\n",
      "---------\n",
      "iter:     0, loss: 0.435988  [   64/60000]\n",
      "iter:   100, loss: 0.548119  [ 6464/60000]\n",
      "iter:   200, loss: 0.361846  [12864/60000]\n",
      "iter:   300, loss: 0.610575  [19264/60000]\n",
      "iter:   400, loss: 0.533366  [25664/60000]\n",
      "iter:   500, loss: 0.535534  [32064/60000]\n",
      "iter:   600, loss: 0.536175  [38464/60000]\n",
      "iter:   700, loss: 0.655007  [44864/60000]\n",
      "iter:   800, loss: 0.618726  [51264/60000]\n",
      "iter:   900, loss: 0.514710  [57664/60000]\n",
      "Accuracy: 81.5% / Avg loss: 0.533370\n",
      "\n",
      "Epoch  34\n",
      "---------\n",
      "iter:     0, loss: 0.429781  [   64/60000]\n",
      "iter:   100, loss: 0.542928  [ 6464/60000]\n",
      "iter:   200, loss: 0.357596  [12864/60000]\n",
      "iter:   300, loss: 0.605245  [19264/60000]\n",
      "iter:   400, loss: 0.528037  [25664/60000]\n",
      "iter:   500, loss: 0.531178  [32064/60000]\n",
      "iter:   600, loss: 0.531211  [38464/60000]\n",
      "iter:   700, loss: 0.655668  [44864/60000]\n",
      "iter:   800, loss: 0.616933  [51264/60000]\n",
      "iter:   900, loss: 0.507951  [57664/60000]\n",
      "Accuracy: 81.5% / Avg loss: 0.529408\n",
      "\n",
      "Epoch  35\n",
      "---------\n",
      "iter:     0, loss: 0.423881  [   64/60000]\n",
      "iter:   100, loss: 0.538092  [ 6464/60000]\n",
      "iter:   200, loss: 0.353591  [12864/60000]\n",
      "iter:   300, loss: 0.600077  [19264/60000]\n",
      "iter:   400, loss: 0.522824  [25664/60000]\n",
      "iter:   500, loss: 0.526804  [32064/60000]\n",
      "iter:   600, loss: 0.526569  [38464/60000]\n",
      "iter:   700, loss: 0.656335  [44864/60000]\n",
      "iter:   800, loss: 0.615208  [51264/60000]\n",
      "iter:   900, loss: 0.501489  [57664/60000]\n",
      "Accuracy: 81.7% / Avg loss: 0.525684\n",
      "\n",
      "Epoch  36\n",
      "---------\n",
      "iter:     0, loss: 0.418241  [   64/60000]\n",
      "iter:   100, loss: 0.533604  [ 6464/60000]\n",
      "iter:   200, loss: 0.349839  [12864/60000]\n",
      "iter:   300, loss: 0.595145  [19264/60000]\n",
      "iter:   400, loss: 0.517706  [25664/60000]\n",
      "iter:   500, loss: 0.522547  [32064/60000]\n",
      "iter:   600, loss: 0.522138  [38464/60000]\n",
      "iter:   700, loss: 0.656950  [44864/60000]\n",
      "iter:   800, loss: 0.613475  [51264/60000]\n",
      "iter:   900, loss: 0.495321  [57664/60000]\n",
      "Accuracy: 81.8% / Avg loss: 0.522170\n",
      "\n",
      "Epoch  37\n",
      "---------\n",
      "iter:     0, loss: 0.412904  [   64/60000]\n",
      "iter:   100, loss: 0.529377  [ 6464/60000]\n",
      "iter:   200, loss: 0.346297  [12864/60000]\n",
      "iter:   300, loss: 0.590472  [19264/60000]\n",
      "iter:   400, loss: 0.512776  [25664/60000]\n",
      "iter:   500, loss: 0.518307  [32064/60000]\n",
      "iter:   600, loss: 0.517958  [38464/60000]\n",
      "iter:   700, loss: 0.657494  [44864/60000]\n",
      "iter:   800, loss: 0.611840  [51264/60000]\n",
      "iter:   900, loss: 0.489475  [57664/60000]\n",
      "Accuracy: 81.9% / Avg loss: 0.518863\n",
      "\n",
      "Epoch  38\n",
      "---------\n",
      "iter:     0, loss: 0.407764  [   64/60000]\n",
      "iter:   100, loss: 0.525444  [ 6464/60000]\n",
      "iter:   200, loss: 0.342935  [12864/60000]\n",
      "iter:   300, loss: 0.586009  [19264/60000]\n",
      "iter:   400, loss: 0.507906  [25664/60000]\n",
      "iter:   500, loss: 0.514121  [32064/60000]\n",
      "iter:   600, loss: 0.513984  [38464/60000]\n",
      "iter:   700, loss: 0.657896  [44864/60000]\n",
      "iter:   800, loss: 0.610269  [51264/60000]\n",
      "iter:   900, loss: 0.483849  [57664/60000]\n",
      "Accuracy: 82.0% / Avg loss: 0.515742\n",
      "\n",
      "Epoch  39\n",
      "---------\n",
      "iter:     0, loss: 0.402785  [   64/60000]\n",
      "iter:   100, loss: 0.521761  [ 6464/60000]\n",
      "iter:   200, loss: 0.339753  [12864/60000]\n",
      "iter:   300, loss: 0.581687  [19264/60000]\n",
      "iter:   400, loss: 0.503125  [25664/60000]\n",
      "iter:   500, loss: 0.510009  [32064/60000]\n",
      "iter:   600, loss: 0.510242  [38464/60000]\n",
      "iter:   700, loss: 0.658162  [44864/60000]\n",
      "iter:   800, loss: 0.608751  [51264/60000]\n",
      "iter:   900, loss: 0.478532  [57664/60000]\n",
      "Accuracy: 81.9% / Avg loss: 0.512788\n",
      "\n",
      "Epoch  40\n",
      "---------\n",
      "iter:     0, loss: 0.398005  [   64/60000]\n",
      "iter:   100, loss: 0.518293  [ 6464/60000]\n",
      "iter:   200, loss: 0.336723  [12864/60000]\n",
      "iter:   300, loss: 0.577524  [19264/60000]\n",
      "iter:   400, loss: 0.498454  [25664/60000]\n",
      "iter:   500, loss: 0.506000  [32064/60000]\n",
      "iter:   600, loss: 0.506693  [38464/60000]\n",
      "iter:   700, loss: 0.658297  [44864/60000]\n",
      "iter:   800, loss: 0.607292  [51264/60000]\n",
      "iter:   900, loss: 0.473488  [57664/60000]\n",
      "Accuracy: 81.9% / Avg loss: 0.509986\n",
      "\n",
      "Epoch  41\n",
      "---------\n",
      "iter:     0, loss: 0.393386  [   64/60000]\n",
      "iter:   100, loss: 0.515011  [ 6464/60000]\n",
      "iter:   200, loss: 0.333859  [12864/60000]\n",
      "iter:   300, loss: 0.573510  [19264/60000]\n",
      "iter:   400, loss: 0.493991  [25664/60000]\n",
      "iter:   500, loss: 0.502041  [32064/60000]\n",
      "iter:   600, loss: 0.503322  [38464/60000]\n",
      "iter:   700, loss: 0.658220  [44864/60000]\n",
      "iter:   800, loss: 0.605826  [51264/60000]\n",
      "iter:   900, loss: 0.468680  [57664/60000]\n",
      "Accuracy: 82.0% / Avg loss: 0.507320\n",
      "\n",
      "Epoch  42\n",
      "---------\n",
      "iter:     0, loss: 0.388937  [   64/60000]\n",
      "iter:   100, loss: 0.511915  [ 6464/60000]\n",
      "iter:   200, loss: 0.331117  [12864/60000]\n",
      "iter:   300, loss: 0.569663  [19264/60000]\n",
      "iter:   400, loss: 0.489663  [25664/60000]\n",
      "iter:   500, loss: 0.498211  [32064/60000]\n",
      "iter:   600, loss: 0.500107  [38464/60000]\n",
      "iter:   700, loss: 0.658039  [44864/60000]\n",
      "iter:   800, loss: 0.604352  [51264/60000]\n",
      "iter:   900, loss: 0.464086  [57664/60000]\n",
      "Accuracy: 82.1% / Avg loss: 0.504782\n",
      "\n",
      "Epoch  43\n",
      "---------\n",
      "iter:     0, loss: 0.384617  [   64/60000]\n",
      "iter:   100, loss: 0.508940  [ 6464/60000]\n",
      "iter:   200, loss: 0.328502  [12864/60000]\n",
      "iter:   300, loss: 0.565986  [19264/60000]\n",
      "iter:   400, loss: 0.485463  [25664/60000]\n",
      "iter:   500, loss: 0.494444  [32064/60000]\n",
      "iter:   600, loss: 0.497028  [38464/60000]\n",
      "iter:   700, loss: 0.657697  [44864/60000]\n",
      "iter:   800, loss: 0.602915  [51264/60000]\n",
      "iter:   900, loss: 0.459757  [57664/60000]\n",
      "Accuracy: 82.2% / Avg loss: 0.502361\n",
      "\n",
      "Epoch  44\n",
      "---------\n",
      "iter:     0, loss: 0.380429  [   64/60000]\n",
      "iter:   100, loss: 0.506121  [ 6464/60000]\n",
      "iter:   200, loss: 0.326012  [12864/60000]\n",
      "iter:   300, loss: 0.562434  [19264/60000]\n",
      "iter:   400, loss: 0.481382  [25664/60000]\n",
      "iter:   500, loss: 0.490818  [32064/60000]\n",
      "iter:   600, loss: 0.494079  [38464/60000]\n",
      "iter:   700, loss: 0.657218  [44864/60000]\n",
      "iter:   800, loss: 0.601491  [51264/60000]\n",
      "iter:   900, loss: 0.455637  [57664/60000]\n",
      "Accuracy: 82.2% / Avg loss: 0.500050\n",
      "\n",
      "Epoch  45\n",
      "---------\n",
      "iter:     0, loss: 0.376390  [   64/60000]\n",
      "iter:   100, loss: 0.503430  [ 6464/60000]\n",
      "iter:   200, loss: 0.323623  [12864/60000]\n",
      "iter:   300, loss: 0.559039  [19264/60000]\n",
      "iter:   400, loss: 0.477445  [25664/60000]\n",
      "iter:   500, loss: 0.487291  [32064/60000]\n",
      "iter:   600, loss: 0.491184  [38464/60000]\n",
      "iter:   700, loss: 0.656596  [44864/60000]\n",
      "iter:   800, loss: 0.600096  [51264/60000]\n",
      "iter:   900, loss: 0.451769  [57664/60000]\n",
      "Accuracy: 82.3% / Avg loss: 0.497837\n",
      "\n",
      "Epoch  46\n",
      "---------\n",
      "iter:     0, loss: 0.372491  [   64/60000]\n",
      "iter:   100, loss: 0.500865  [ 6464/60000]\n",
      "iter:   200, loss: 0.321358  [12864/60000]\n",
      "iter:   300, loss: 0.555754  [19264/60000]\n",
      "iter:   400, loss: 0.473660  [25664/60000]\n",
      "iter:   500, loss: 0.483897  [32064/60000]\n",
      "iter:   600, loss: 0.488350  [38464/60000]\n",
      "iter:   700, loss: 0.655857  [44864/60000]\n",
      "iter:   800, loss: 0.598722  [51264/60000]\n",
      "iter:   900, loss: 0.448112  [57664/60000]\n",
      "Accuracy: 82.3% / Avg loss: 0.495713\n",
      "\n",
      "Epoch  47\n",
      "---------\n",
      "iter:     0, loss: 0.368727  [   64/60000]\n",
      "iter:   100, loss: 0.498402  [ 6464/60000]\n",
      "iter:   200, loss: 0.319221  [12864/60000]\n",
      "iter:   300, loss: 0.552622  [19264/60000]\n",
      "iter:   400, loss: 0.469937  [25664/60000]\n",
      "iter:   500, loss: 0.480599  [32064/60000]\n",
      "iter:   600, loss: 0.485634  [38464/60000]\n",
      "iter:   700, loss: 0.655012  [44864/60000]\n",
      "iter:   800, loss: 0.597358  [51264/60000]\n",
      "iter:   900, loss: 0.444610  [57664/60000]\n",
      "Accuracy: 82.4% / Avg loss: 0.493675\n",
      "\n",
      "Epoch  48\n",
      "---------\n",
      "iter:     0, loss: 0.365043  [   64/60000]\n",
      "iter:   100, loss: 0.496055  [ 6464/60000]\n",
      "iter:   200, loss: 0.317185  [12864/60000]\n",
      "iter:   300, loss: 0.549599  [19264/60000]\n",
      "iter:   400, loss: 0.466359  [25664/60000]\n",
      "iter:   500, loss: 0.477421  [32064/60000]\n",
      "iter:   600, loss: 0.482986  [38464/60000]\n",
      "iter:   700, loss: 0.654034  [44864/60000]\n",
      "iter:   800, loss: 0.596041  [51264/60000]\n",
      "iter:   900, loss: 0.441335  [57664/60000]\n",
      "Accuracy: 82.5% / Avg loss: 0.491712\n",
      "\n",
      "Epoch  49\n",
      "---------\n",
      "iter:     0, loss: 0.361482  [   64/60000]\n",
      "iter:   100, loss: 0.493761  [ 6464/60000]\n",
      "iter:   200, loss: 0.315195  [12864/60000]\n",
      "iter:   300, loss: 0.546698  [19264/60000]\n",
      "iter:   400, loss: 0.462856  [25664/60000]\n",
      "iter:   500, loss: 0.474363  [32064/60000]\n",
      "iter:   600, loss: 0.480423  [38464/60000]\n",
      "iter:   700, loss: 0.652931  [44864/60000]\n",
      "iter:   800, loss: 0.594714  [51264/60000]\n",
      "iter:   900, loss: 0.438221  [57664/60000]\n",
      "Accuracy: 82.7% / Avg loss: 0.489822\n",
      "\n",
      "Epoch  50\n",
      "---------\n",
      "iter:     0, loss: 0.358040  [   64/60000]\n",
      "iter:   100, loss: 0.491541  [ 6464/60000]\n",
      "iter:   200, loss: 0.313264  [12864/60000]\n",
      "iter:   300, loss: 0.543905  [19264/60000]\n",
      "iter:   400, loss: 0.459500  [25664/60000]\n",
      "iter:   500, loss: 0.471374  [32064/60000]\n",
      "iter:   600, loss: 0.477927  [38464/60000]\n",
      "iter:   700, loss: 0.651743  [44864/60000]\n",
      "iter:   800, loss: 0.593382  [51264/60000]\n",
      "iter:   900, loss: 0.435284  [57664/60000]\n",
      "Accuracy: 82.8% / Avg loss: 0.488000\n",
      "\n",
      "Epoch  51\n",
      "---------\n",
      "iter:     0, loss: 0.354684  [   64/60000]\n",
      "iter:   100, loss: 0.489404  [ 6464/60000]\n",
      "iter:   200, loss: 0.311398  [12864/60000]\n",
      "iter:   300, loss: 0.541264  [19264/60000]\n",
      "iter:   400, loss: 0.456242  [25664/60000]\n",
      "iter:   500, loss: 0.468473  [32064/60000]\n",
      "iter:   600, loss: 0.475525  [38464/60000]\n",
      "iter:   700, loss: 0.650453  [44864/60000]\n",
      "iter:   800, loss: 0.592035  [51264/60000]\n",
      "iter:   900, loss: 0.432509  [57664/60000]\n",
      "Accuracy: 82.7% / Avg loss: 0.486244\n",
      "\n",
      "Epoch  52\n",
      "---------\n",
      "iter:     0, loss: 0.351448  [   64/60000]\n",
      "iter:   100, loss: 0.487368  [ 6464/60000]\n",
      "iter:   200, loss: 0.309568  [12864/60000]\n",
      "iter:   300, loss: 0.538687  [19264/60000]\n",
      "iter:   400, loss: 0.453077  [25664/60000]\n",
      "iter:   500, loss: 0.465706  [32064/60000]\n",
      "iter:   600, loss: 0.473231  [38464/60000]\n",
      "iter:   700, loss: 0.649119  [44864/60000]\n",
      "iter:   800, loss: 0.590712  [51264/60000]\n",
      "iter:   900, loss: 0.429911  [57664/60000]\n",
      "Accuracy: 82.8% / Avg loss: 0.484548\n",
      "\n",
      "Epoch  53\n",
      "---------\n",
      "iter:     0, loss: 0.348302  [   64/60000]\n",
      "iter:   100, loss: 0.485377  [ 6464/60000]\n",
      "iter:   200, loss: 0.307812  [12864/60000]\n",
      "iter:   300, loss: 0.536174  [19264/60000]\n",
      "iter:   400, loss: 0.450012  [25664/60000]\n",
      "iter:   500, loss: 0.463044  [32064/60000]\n",
      "iter:   600, loss: 0.470971  [38464/60000]\n",
      "iter:   700, loss: 0.647747  [44864/60000]\n",
      "iter:   800, loss: 0.589340  [51264/60000]\n",
      "iter:   900, loss: 0.427446  [57664/60000]\n",
      "Accuracy: 82.9% / Avg loss: 0.482907\n",
      "\n",
      "Epoch  54\n",
      "---------\n",
      "iter:     0, loss: 0.345261  [   64/60000]\n",
      "iter:   100, loss: 0.483444  [ 6464/60000]\n",
      "iter:   200, loss: 0.306120  [12864/60000]\n",
      "iter:   300, loss: 0.533767  [19264/60000]\n",
      "iter:   400, loss: 0.447025  [25664/60000]\n",
      "iter:   500, loss: 0.460467  [32064/60000]\n",
      "iter:   600, loss: 0.468801  [38464/60000]\n",
      "iter:   700, loss: 0.646322  [44864/60000]\n",
      "iter:   800, loss: 0.587979  [51264/60000]\n",
      "iter:   900, loss: 0.425146  [57664/60000]\n",
      "Accuracy: 83.0% / Avg loss: 0.481318\n",
      "\n",
      "Epoch  55\n",
      "---------\n",
      "iter:     0, loss: 0.342312  [   64/60000]\n",
      "iter:   100, loss: 0.481574  [ 6464/60000]\n",
      "iter:   200, loss: 0.304495  [12864/60000]\n",
      "iter:   300, loss: 0.531459  [19264/60000]\n",
      "iter:   400, loss: 0.444104  [25664/60000]\n",
      "iter:   500, loss: 0.457986  [32064/60000]\n",
      "iter:   600, loss: 0.466701  [38464/60000]\n",
      "iter:   700, loss: 0.644886  [44864/60000]\n",
      "iter:   800, loss: 0.586709  [51264/60000]\n",
      "iter:   900, loss: 0.422914  [57664/60000]\n",
      "Accuracy: 83.0% / Avg loss: 0.479775\n",
      "\n",
      "Epoch  56\n",
      "---------\n",
      "iter:     0, loss: 0.339430  [   64/60000]\n",
      "iter:   100, loss: 0.479689  [ 6464/60000]\n",
      "iter:   200, loss: 0.302921  [12864/60000]\n",
      "iter:   300, loss: 0.529204  [19264/60000]\n",
      "iter:   400, loss: 0.441295  [25664/60000]\n",
      "iter:   500, loss: 0.455588  [32064/60000]\n",
      "iter:   600, loss: 0.464652  [38464/60000]\n",
      "iter:   700, loss: 0.643346  [44864/60000]\n",
      "iter:   800, loss: 0.585441  [51264/60000]\n",
      "iter:   900, loss: 0.420864  [57664/60000]\n",
      "Accuracy: 83.0% / Avg loss: 0.478275\n",
      "\n",
      "Epoch  57\n",
      "---------\n",
      "iter:     0, loss: 0.336689  [   64/60000]\n",
      "iter:   100, loss: 0.477876  [ 6464/60000]\n",
      "iter:   200, loss: 0.301377  [12864/60000]\n",
      "iter:   300, loss: 0.527039  [19264/60000]\n",
      "iter:   400, loss: 0.438530  [25664/60000]\n",
      "iter:   500, loss: 0.453241  [32064/60000]\n",
      "iter:   600, loss: 0.462648  [38464/60000]\n",
      "iter:   700, loss: 0.641805  [44864/60000]\n",
      "iter:   800, loss: 0.584170  [51264/60000]\n",
      "iter:   900, loss: 0.418951  [57664/60000]\n",
      "Accuracy: 83.1% / Avg loss: 0.476819\n",
      "\n",
      "Epoch  58\n",
      "---------\n",
      "iter:     0, loss: 0.334022  [   64/60000]\n",
      "iter:   100, loss: 0.476038  [ 6464/60000]\n",
      "iter:   200, loss: 0.299864  [12864/60000]\n",
      "iter:   300, loss: 0.524930  [19264/60000]\n",
      "iter:   400, loss: 0.435809  [25664/60000]\n",
      "iter:   500, loss: 0.450987  [32064/60000]\n",
      "iter:   600, loss: 0.460686  [38464/60000]\n",
      "iter:   700, loss: 0.640176  [44864/60000]\n",
      "iter:   800, loss: 0.582873  [51264/60000]\n",
      "iter:   900, loss: 0.417140  [57664/60000]\n",
      "Accuracy: 83.1% / Avg loss: 0.475398\n",
      "\n",
      "Epoch  59\n",
      "---------\n",
      "iter:     0, loss: 0.331479  [   64/60000]\n",
      "iter:   100, loss: 0.474270  [ 6464/60000]\n",
      "iter:   200, loss: 0.298391  [12864/60000]\n",
      "iter:   300, loss: 0.522913  [19264/60000]\n",
      "iter:   400, loss: 0.433207  [25664/60000]\n",
      "iter:   500, loss: 0.448805  [32064/60000]\n",
      "iter:   600, loss: 0.458793  [38464/60000]\n",
      "iter:   700, loss: 0.638502  [44864/60000]\n",
      "iter:   800, loss: 0.581609  [51264/60000]\n",
      "iter:   900, loss: 0.415426  [57664/60000]\n",
      "Accuracy: 83.2% / Avg loss: 0.474016\n",
      "\n",
      "Epoch  60\n",
      "---------\n",
      "iter:     0, loss: 0.329002  [   64/60000]\n",
      "iter:   100, loss: 0.472548  [ 6464/60000]\n",
      "iter:   200, loss: 0.296974  [12864/60000]\n",
      "iter:   300, loss: 0.520957  [19264/60000]\n",
      "iter:   400, loss: 0.430642  [25664/60000]\n",
      "iter:   500, loss: 0.446731  [32064/60000]\n",
      "iter:   600, loss: 0.456976  [38464/60000]\n",
      "iter:   700, loss: 0.636897  [44864/60000]\n",
      "iter:   800, loss: 0.580263  [51264/60000]\n",
      "iter:   900, loss: 0.413765  [57664/60000]\n",
      "Accuracy: 83.2% / Avg loss: 0.472666\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"훈련 및 평가\n",
    "\"\"\"\n",
    "\n",
    "# 장치 확인하기\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "EPOCHS = 60\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {t+1:>3d}\\n---------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
